{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Analysis\n",
    "---\n",
    "- Churn refers to the number of customers who stop doing business with a company within a given time period. <br><br>\n",
    "- A high churn rate can be a sign of customer dissatisfaction or a problem with the company's products or services. It can also be caused by factors outside of the company's control, such as a competitor offering a better deal.<br><br>\n",
    "- Churning customers can have a number of economic disadvantages for a business, including:<br>\n",
    "    - Loss of revenue. When customers churn, they stop paying for the company's products or services. This can lead to a significant loss of revenue, especially for businesses that rely on recurring revenue.<br><br>\n",
    "    - Increased marketing costs. To replace lost customers, businesses often need to spend more on marketing and sales. This can be a significant expense, especially for businesses with a high churn rate.<br><br>\n",
    "    - Damage to brand reputation. When customers churn, they may spread negative word-of-mouth about the company. This can damage the company's brand reputation and make it more difficult to attract new customers.<br><br>\n",
    "    - Increased customer acquisition costs. It is more expensive to acquire new customers than to retain existing customers. This is because new customers are less likely to be familiar with the company's products or services and may require more hand-holding.<br><br>\n",
    "    - Decreased customer lifetime value. The customer lifetime value (CLV) is the total amount of money that a customer is expected to spend with a company over their lifetime. When customers churn, the company loses out on the potential future revenue that they could have generated from that customer.<br><br>\n",
    "\n",
    "- The economic disadvantages of churning customers can be significant, so it is important for businesses to take steps to reduce churn. Some common ways to reduce churn include:<br><br>\n",
    "\n",
    "    - Providing excellent customer service. This means being responsive to customer inquiries, resolving problems quickly and efficiently, and going the extra mile to make sure that customers are satisfied.<br><br>\n",
    "    - Offering competitive prices. This means keeping prices in line with the competition and offering discounts and promotions to encourage customers to stay with the company.<br><br>\n",
    "    - Constantly innovating. This means keeping up with the latest trends and offering new and improved products and services to keep customers engaged.<br><br>\n",
    "    - Personalizing the customer experience. This means getting to know each customer's individual needs and preferences and tailoring the company's offerings accordingly.\n",
    "<br><br>\n",
    "- By taking steps to reduce churn, businesses can improve their bottom line and ensure long-term success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('bank_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CreditScore Geography  Gender Age Tenure    Balance NumOfProducts  \\\n",
       "0            619    France  Female  42      2        0.0             1   \n",
       "1            608     Spain  Female  41      1   83807.86             1   \n",
       "2            502    France  Female  42      8   159660.8             3   \n",
       "3            699    France  Female  39      1        0.0             2   \n",
       "4            850     Spain  Female  43      2  125510.82             1   \n",
       "...          ...       ...     ...  ..    ...        ...           ...   \n",
       "9995         771    France    Male  39      5        0.0             2   \n",
       "9996         516    France    Male  35     10   57369.61             1   \n",
       "9997         709    France  Female  36      7        0.0             1   \n",
       "9998         772   Germany    Male  42      3   75075.31             2   \n",
       "9999         792    France  Female  28      4  130142.79             1   \n",
       "\n",
       "     HasCrCard IsActiveMember EstimatedSalary  \n",
       "0            1              1       101348.88  \n",
       "1            0              1       112542.58  \n",
       "2            1              0       113931.57  \n",
       "3            0              0        93826.63  \n",
       "4            1              1         79084.1  \n",
       "...        ...            ...             ...  \n",
       "9995         1              0        96270.64  \n",
       "9996         1              1       101699.77  \n",
       "9997         0              1        42085.58  \n",
       "9998         1              0        92888.52  \n",
       "9999         1              0        38190.78  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X, columns = [\"CreditScore\",\"Geography\",\"Gender\",\"Age\",\"Tenure\",\"Balance\",\"NumOfProducts\",\"HasCrCard\",\"IsActiveMember\",\"EstimatedSalary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Exited\n",
       "0          1\n",
       "1          0\n",
       "2          1\n",
       "3          0\n",
       "4          0\n",
       "...      ...\n",
       "9995       0\n",
       "9996       0\n",
       "9997       1\n",
       "9998       1\n",
       "9999       0\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y, columns = [\"Exited\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "VYP9cQTWbzuI",
    "outputId": "797e7a64-9bac-436a-8c9c-94437e5e7587"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "38vKGE6Nb2RR",
    "outputId": "a815e42a-e0dd-4cb5-ab97-b17ead98fbc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6bQ0UgSU-NJ"
   },
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le5MJreAbW52"
   },
   "source": [
    "Label Encoding the \"Gender\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxVKWXxLbczC"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "-M1KboxFb6OO",
    "outputId": "e2b8c7e8-0cbc-4cdf-f4eb-7f0853a00b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 0 ... 1 1 101348.88]\n",
      " [608 'Spain' 0 ... 0 1 112542.58]\n",
      " [502 'France' 0 ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 0 ... 0 1 42085.58]\n",
      " [772 'Germany' 1 ... 1 0 92888.52]\n",
      " [792 'France' 0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUxGZezpbMcb"
   },
   "source": [
    "One Hot Encoding the \"Geography\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMXC8-KMVirw"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "ZcxwEon-b8nV",
    "outputId": "23a98af4-5e33-4b26-c27b-f06e3c5d2baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHol938cW8zd"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-TDt0Y_XEfc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, ..., 1, 1, 101348.88],\n",
       "       [0.0, 0.0, 1.0, ..., 0, 1, 112542.58],\n",
       "       [1.0, 0.0, 0.0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [1.0, 0.0, 0.0, ..., 0, 1, 42085.58],\n",
       "       [0.0, 1.0, 0.0, ..., 1, 0, 92888.52],\n",
       "       [1.0, 0.0, 0.0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE_FcHyfV3TQ"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViCrE00rV8Sk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "## Part 2 - Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nHZ-LKv_ZRb3",
    "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 992us/step - loss: 0.5034 - accuracy: 0.7960\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 907us/step - loss: 0.4608 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 995us/step - loss: 0.4483 - accuracy: 0.7960\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.4408 - accuracy: 0.7960\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 938us/step - loss: 0.4363 - accuracy: 0.7960\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 958us/step - loss: 0.4329 - accuracy: 0.7976\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 941us/step - loss: 0.4304 - accuracy: 0.8015\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 955us/step - loss: 0.4281 - accuracy: 0.8046\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 916us/step - loss: 0.4263 - accuracy: 0.8075\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 906us/step - loss: 0.4245 - accuracy: 0.8112\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 913us/step - loss: 0.4228 - accuracy: 0.8155\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 954us/step - loss: 0.4208 - accuracy: 0.8189\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 984us/step - loss: 0.4189 - accuracy: 0.8209\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 929us/step - loss: 0.4165 - accuracy: 0.8234\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 998us/step - loss: 0.4140 - accuracy: 0.8257\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4117 - accuracy: 0.8265\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 930us/step - loss: 0.4092 - accuracy: 0.8310\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 975us/step - loss: 0.4072 - accuracy: 0.8311\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 944us/step - loss: 0.4052 - accuracy: 0.8321\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 979us/step - loss: 0.4035 - accuracy: 0.8334\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 902us/step - loss: 0.4019 - accuracy: 0.8353\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 905us/step - loss: 0.4008 - accuracy: 0.8345\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 902us/step - loss: 0.3999 - accuracy: 0.8336\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 904us/step - loss: 0.3989 - accuracy: 0.8357\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 908us/step - loss: 0.3981 - accuracy: 0.8350\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 900us/step - loss: 0.3975 - accuracy: 0.8341\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 897us/step - loss: 0.3970 - accuracy: 0.8359\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 904us/step - loss: 0.3965 - accuracy: 0.8359\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 931us/step - loss: 0.3958 - accuracy: 0.8376\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.8364\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 930us/step - loss: 0.3949 - accuracy: 0.8369\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3949 - accuracy: 0.8364\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8369\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3938 - accuracy: 0.8366\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8365\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3932 - accuracy: 0.8371\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 969us/step - loss: 0.3928 - accuracy: 0.8376\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 955us/step - loss: 0.3922 - accuracy: 0.8382\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 960us/step - loss: 0.3917 - accuracy: 0.8381\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 942us/step - loss: 0.3914 - accuracy: 0.8378\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.8390\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3907 - accuracy: 0.8395\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8389\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3895 - accuracy: 0.8404\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8400\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8399\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3880 - accuracy: 0.8403\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3869 - accuracy: 0.8399\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3860 - accuracy: 0.8404\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3848 - accuracy: 0.8396\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3835 - accuracy: 0.8413\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3812 - accuracy: 0.8415\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 952us/step - loss: 0.3800 - accuracy: 0.8411\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3774 - accuracy: 0.8426\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3752 - accuracy: 0.8421\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8454\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8461\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 942us/step - loss: 0.3643 - accuracy: 0.8499\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 941us/step - loss: 0.3612 - accuracy: 0.8487\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 968us/step - loss: 0.3579 - accuracy: 0.8510\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8526\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8535\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3509 - accuracy: 0.8546\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 953us/step - loss: 0.3489 - accuracy: 0.8570\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 930us/step - loss: 0.3474 - accuracy: 0.8580\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 953us/step - loss: 0.3460 - accuracy: 0.8580\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3450 - accuracy: 0.8591\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 907us/step - loss: 0.3444 - accuracy: 0.8593\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 965us/step - loss: 0.3437 - accuracy: 0.8589\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 959us/step - loss: 0.3428 - accuracy: 0.8595\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 947us/step - loss: 0.3420 - accuracy: 0.8602\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 917us/step - loss: 0.3413 - accuracy: 0.8619\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 947us/step - loss: 0.3400 - accuracy: 0.8602\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 915us/step - loss: 0.3399 - accuracy: 0.8625\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 915us/step - loss: 0.3397 - accuracy: 0.8601\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 897us/step - loss: 0.3387 - accuracy: 0.8614\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 936us/step - loss: 0.3384 - accuracy: 0.8615\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 916us/step - loss: 0.3382 - accuracy: 0.8634\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 911us/step - loss: 0.3375 - accuracy: 0.8622\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 916us/step - loss: 0.3367 - accuracy: 0.8620\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 935us/step - loss: 0.3370 - accuracy: 0.8629\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8611\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 914us/step - loss: 0.3366 - accuracy: 0.8636\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 965us/step - loss: 0.3364 - accuracy: 0.8621\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 917us/step - loss: 0.3360 - accuracy: 0.8641\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 911us/step - loss: 0.3357 - accuracy: 0.8621\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 920us/step - loss: 0.3358 - accuracy: 0.8625\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 914us/step - loss: 0.3354 - accuracy: 0.8641\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 950us/step - loss: 0.3350 - accuracy: 0.8659\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 943us/step - loss: 0.3344 - accuracy: 0.8652\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8660\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8630\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8646\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8655\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 988us/step - loss: 0.3338 - accuracy: 0.8652\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8639\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 979us/step - loss: 0.3340 - accuracy: 0.8650\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 902us/step - loss: 0.3336 - accuracy: 0.8652\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8637\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25da8d5ff10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "## Part 4 - Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7yx47jPZt11"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "nIyEeQdRZwgs",
    "outputId": "82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 967us/step\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
    "\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0oyfLWoaEGw"
   },
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ci6K_r6LaF6P",
    "outputId": "4d854e9e-22d5-432f-f6e5-a102fe3ae0bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1505   90]\n",
      " [ 196  209]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.857"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x750 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework**\n",
    "- Use the dataset: https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset.\n",
    "- Experiment with the number of hidden layers, and the number of units in the hidden layer.\n",
    "- Try to experiment on the activation functions in the hidden layer https://www.tensorflow.org/api_docs/python/tf/keras/activations\n",
    "- Try to experiment with the optimizer: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "- Check the accuracy, specificity, and sensitivity of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "artificial_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
