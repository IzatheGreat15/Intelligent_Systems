{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Prediction Model\n",
    "\n",
    "This is a binary classification neural network model. The goal of this model is to be able to predict whether the patient is a diabetic (postive) or not (negative) based on the given history of the dataset.\n",
    "\n",
    "### Aboout the Dataset\n",
    "The Diabetes prediction dataset is a collection of medical and demographic data from patients, along with their diabetes status (positive or negative). The data includes features such as age, gender, body mass index (BMI), hypertension, heart disease, smoking history, HbA1c level, and blood glucose level.\n",
    "\n",
    "### Attributes Description\n",
    "\n",
    "##### gender\n",
    "- Gender refers to the biological sex of the individual, which can have an impact on their susceptibility to diabetes. \n",
    "- 3 Categories: \n",
    "    - ***Male***\n",
    "    - ***Female***\n",
    "    - ***Other***\n",
    "##### age\n",
    "- Age is an important factor as diabetes is more commonly diagnosed in older adults.\n",
    "- Age ranges from ***0-80*** in our dataset.\n",
    "##### hypertension\n",
    "- Hypertension is a medical condition in which the blood pressure in the arteries is persistently elevated. \n",
    "- Values:\n",
    "    - 0 => no hypertension \n",
    "    - 1 => have hypertension\n",
    "##### heart_disease\n",
    "- Heart disease is another medical condition that is associated with an increased risk of developing diabetes. \n",
    "- Values:\n",
    "    - 0 => no heart disease \n",
    "    - 1 => have heart disease\n",
    "##### smoking_history\n",
    "- Smoking history is also considered a risk factor for diabetes and can exacerbate the complications associated with diabetes.\n",
    "- 5 Categories: \n",
    "    - ***Not Current***\n",
    "    - ***Former***\n",
    "    - ***No Info***\n",
    "    - ***Current***\n",
    "    - ***Never***\n",
    "##### bmi\n",
    "- BMI (Body Mass Index) is a measure of body fat based on weight and height. Higher BMI values are linked to a higher risk of diabetes. \n",
    "- The range of BMI in the dataset is from ***10.16 to 71.55***. BMI less than 18.5 is underweight, 18.5-24.9 is normal, 25-29.9 is overweight, and 30 or more is obese.\n",
    "- Values:\n",
    "\n",
    "|                      |             |\n",
    "|----------------------|-------------|\n",
    "| BMI < 18.5           | underweight |\n",
    "| 18.5 <= BMI <= 24.9  | normal      |\n",
    "| 25 <= BMI <= 29.9    | overweight  |\n",
    "| BMI > 30             | obese       |\n",
    "\n",
    "##### HbA1c_level\n",
    "- HbA1c (Hemoglobin A1c) level is a measure of a person's average blood sugar level over the past 2-3 months. \n",
    "- Higher levels indicate a greater risk of developing diabetes. \n",
    "- Mostly ***more than 6.5%*** of HbA1c Level indicates diabetes.\n",
    "##### blood_glucose_level\n",
    "- Blood glucose level refers to the amount of glucose in the bloodstream at a given time. \n",
    "- High blood glucose levels are a key indicator of diabetes.\n",
    "##### diabetes (***Output variable***)\n",
    "- Diabetes is the target variable being predicted.\n",
    "- Values:\n",
    "    - 0 => no diabetes\n",
    "    - 1 => have diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Data Preprocessing\n",
    "\n",
    "importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17.37</td>\n",
       "      <td>6.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Female</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0      Female  80.0             0              1           never  25.19   \n",
       "1      Female  54.0             0              0         No Info  27.32   \n",
       "2        Male  28.0             0              0           never  27.32   \n",
       "3      Female  36.0             0              0         current  23.45   \n",
       "4        Male  76.0             1              1         current  20.14   \n",
       "...       ...   ...           ...            ...             ...    ...   \n",
       "99995  Female  80.0             0              0         No Info  27.32   \n",
       "99996  Female   2.0             0              0         No Info  17.37   \n",
       "99997    Male  66.0             0              0          former  27.83   \n",
       "99998  Female  24.0             0              0           never  35.42   \n",
       "99999  Female  57.0             0              0         current  22.43   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  diabetes  \n",
       "0              6.6                  140         0  \n",
       "1              6.6                   80         0  \n",
       "2              5.7                  158         0  \n",
       "3              5.0                  155         0  \n",
       "4              4.8                  155         0  \n",
       "...            ...                  ...       ...  \n",
       "99995          6.2                   90         0  \n",
       "99996          6.5                  100         0  \n",
       "99997          5.7                  155         0  \n",
       "99998          4.0                  100         0  \n",
       "99999          6.6                   90         0  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "# Print the dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the Dataset\n",
    "\n",
    "Split the dataset into two parts:\n",
    "- *input_varibles* - input features that are used to make the prediction\n",
    "- *output_variable* - target variable to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all rows\n",
    "# get the first columns till the second to the last column\n",
    "# -1 denotes not including the last column\n",
    "input_variables = dataset.iloc[:, 0:-1]\n",
    "\n",
    "# get all rows\n",
    "# get only the last column\n",
    "output_variable = dataset.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.2</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17.37</td>\n",
       "      <td>6.5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Female</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0      Female  80.0             0              1           never  25.19   \n",
       "1      Female  54.0             0              0         No Info  27.32   \n",
       "2        Male  28.0             0              0           never  27.32   \n",
       "3      Female  36.0             0              0         current  23.45   \n",
       "4        Male  76.0             1              1         current  20.14   \n",
       "...       ...   ...           ...            ...             ...    ...   \n",
       "99995  Female  80.0             0              0         No Info  27.32   \n",
       "99996  Female   2.0             0              0         No Info  17.37   \n",
       "99997    Male  66.0             0              0          former  27.83   \n",
       "99998  Female  24.0             0              0           never  35.42   \n",
       "99999  Female  57.0             0              0         current  22.43   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  \n",
       "0              6.6                  140  \n",
       "1              6.6                   80  \n",
       "2              5.7                  158  \n",
       "3              5.0                  155  \n",
       "4              4.8                  155  \n",
       "...            ...                  ...  \n",
       "99995          6.2                   90  \n",
       "99996          6.5                  100  \n",
       "99997          5.7                  155  \n",
       "99998          4.0                  100  \n",
       "99999          6.6                   90  \n",
       "\n",
       "[100000 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       diabetes\n",
       "0             0\n",
       "1             0\n",
       "2             0\n",
       "3             0\n",
       "4             0\n",
       "...         ...\n",
       "99995         0\n",
       "99996         0\n",
       "99997         0\n",
       "99998         0\n",
       "99999         0\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_variable = pd.DataFrame(output_variable, columns=[\"diabetes\"])\n",
    "\n",
    "output_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Categorical Data\n",
    "\n",
    "Since most algorithms, perform mathematical operations, it is better to have numerical inputs instead of categorical data like gender, country.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the *Label Encoding* for the *Gender* column because it only has 2 values: \n",
    "\n",
    "    0 => Female, 1 => Male. \n",
    "    \n",
    "*Label Encoding* is simple and efficient, it reduces the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.2</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17.37</td>\n",
       "      <td>6.5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0           0  80.0             0              1           never  25.19   \n",
       "1           0  54.0             0              0         No Info  27.32   \n",
       "2           1  28.0             0              0           never  27.32   \n",
       "3           0  36.0             0              0         current  23.45   \n",
       "4           1  76.0             1              1         current  20.14   \n",
       "...       ...   ...           ...            ...             ...    ...   \n",
       "99995       0  80.0             0              0         No Info  27.32   \n",
       "99996       0   2.0             0              0         No Info  17.37   \n",
       "99997       1  66.0             0              0          former  27.83   \n",
       "99998       0  24.0             0              0           never  35.42   \n",
       "99999       0  57.0             0              0         current  22.43   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  \n",
       "0              6.6                  140  \n",
       "1              6.6                   80  \n",
       "2              5.7                  158  \n",
       "3              5.0                  155  \n",
       "4              4.8                  155  \n",
       "...            ...                  ...  \n",
       "99995          6.2                   90  \n",
       "99996          6.5                  100  \n",
       "99997          5.7                  155  \n",
       "99998          4.0                  100  \n",
       "99999          6.6                   90  \n",
       "\n",
       "[100000 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the gender column\n",
    "input_variables['gender'] = label_encoder.fit_transform(input_variables['gender'])\n",
    "\n",
    "input_variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the *One Hot Encoder* for the *smoking_history*, as it is a nominal categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.  ,   0.  ,   0.  , ...,  25.19,   6.6 , 140.  ],\n",
       "       [  1.  ,   0.  ,   0.  , ...,  27.32,   6.6 ,  80.  ],\n",
       "       [  0.  ,   0.  ,   0.  , ...,  27.32,   5.7 , 158.  ],\n",
       "       ...,\n",
       "       [  0.  ,   0.  ,   0.  , ...,  27.83,   5.7 , 155.  ],\n",
       "       [  0.  ,   0.  ,   0.  , ...,  35.42,   4.  , 100.  ],\n",
       "       [  0.  ,   1.  ,   0.  , ...,  22.43,   6.6 ,  90.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Initialize ColumnTransformer with OneHotEncoder\n",
    "column_transformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [4])], remainder='passthrough')\n",
    "\n",
    "# Fit and transform smoking_history column and convert to a DataFrame\n",
    "input_variables = np.array(column_transformer.fit_transform(input_variables))\n",
    "\n",
    "input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the Dataset: Training set and Testing set\n",
    "\n",
    "Purpose:\n",
    "- to evaluate how well the ML model is likely to perform unseen data\n",
    "- reserving a portion of your data for testing, you can assess the model's generalization performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  ,   0.  ,   0.  , ...,  27.32,   4.8 , 159.  ],\n",
       "       [  1.  ,   0.  ,   0.  , ...,  16.02,   5.8 ,  90.  ],\n",
       "       [  0.  ,   1.  ,   0.  , ...,  27.28,   6.6 , 159.  ],\n",
       "       ...,\n",
       "       [  0.  ,   0.  ,   0.  , ...,  41.23,   9.  , 145.  ],\n",
       "       [  0.  ,   0.  ,   0.  , ...,  30.18,   5.8 ,  90.  ],\n",
       "       [  1.  ,   0.  ,   0.  , ...,  27.32,   4.5 , 158.  ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into features(input) and target(output)\n",
    "input, output = input_variables, np.array(output_variable)\n",
    "\n",
    "# Split into 70(training)/30(testing)\n",
    "input_train, input_test, output_train, output_test = train_test_split(input, output, test_size=0.3, random_state=0)\n",
    "\n",
    "input_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.  ,   0.  ,   0.  , ...,  27.32,   4.8 , 140.  ],\n",
       "       [  0.  ,   0.  ,   0.  , ...,  27.32,   4.8 , 100.  ],\n",
       "       [  0.  ,   1.  ,   0.  , ...,  37.16,   6.6 ,  85.  ],\n",
       "       ...,\n",
       "       [  0.  ,   1.  ,   0.  , ...,  27.32,   6.2 , 145.  ],\n",
       "       [  1.  ,   0.  ,   0.  , ...,  25.58,   5.7 , 200.  ],\n",
       "       [  0.  ,   0.  ,   0.  , ...,  21.68,   5.7 , 155.  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling\n",
    "\n",
    "Feature scaling is a preprocessing technique in machine learning that transforms the numerical features of a dataset into a specific range or distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "input_train = standard_scaler.fit_transform(input_train)\n",
    "input_test = standard_scaler.fit_transform(input_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Artificial Neural Network(ANN)\n",
    "\n",
    "In this step, we will begin developing the model.\n",
    "\n",
    "##### General Outline of the proccess\n",
    "\n",
    "- **Run Individual Experiments**\n",
    "\n",
    "1. Experiment with different numbers of hidden layers and units per layer\n",
    "2. Experiment with different activation functions in the hidden layers\n",
    "3. Experiment with different optimizers\n",
    "\n",
    "\n",
    "- **Analysis of Individual Experiments**\n",
    "\n",
    "    Analyze how each factors affects the model performance. For each of the experiments, pick out the best configurations for the model.\n",
    "\n",
    "- **Combining Factors for the Final Architecture of the Model**\n",
    "\n",
    "    Combine the best-performing cofinguration from each of the categories(architecture, activation featuers, and optimizer).\n",
    "\n",
    "- **Training the Final Model**\n",
    "\n",
    "    Train the final nueral network model usng the training data\n",
    "\n",
    "- **Evaluation and Validation**\n",
    "\n",
    "    Evaluate the final model's performance on a separate validation dataset to ensure it generalizes well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment with the architecture(number of hidden layers and unit per layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different architectures\n",
    "num_hidden_layers = [1, 2, 3] \n",
    "num_units_per_layer = [12, 24, 36] \n",
    "\n",
    "# Result object for test loss and accuracy\n",
    "results = {}\n",
    "\n",
    "# Initialize variables to keep track of the best configuration and performance\n",
    "best_architecture = None\n",
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1s 814us/step - loss: 0.1065 - accuracy: 0.9659\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.1024 - accuracy: 0.9665\n",
      "938/938 [==============================] - 1s 846us/step - loss: 0.0991 - accuracy: 0.9690\n",
      "938/938 [==============================] - 1s 879us/step - loss: 0.0971 - accuracy: 0.9687\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0904 - accuracy: 0.9695\n",
      "938/938 [==============================] - 1s 881us/step - loss: 0.0874 - accuracy: 0.9710\n",
      "938/938 [==============================] - 1s 856us/step - loss: 0.0872 - accuracy: 0.9702\n",
      "938/938 [==============================] - 1s 884us/step - loss: 0.0869 - accuracy: 0.9705\n",
      "938/938 [==============================] - 1s 871us/step - loss: 0.0868 - accuracy: 0.9707\n",
      "Hidden Layers: 1, Units per Layer: 12\n",
      "Test Loss: 0.1065, Test Accuracy: 0.9659\n",
      "\n",
      "Hidden Layers: 1, Units per Layer: 24\n",
      "Test Loss: 0.1024, Test Accuracy: 0.9665\n",
      "\n",
      "Hidden Layers: 1, Units per Layer: 36\n",
      "Test Loss: 0.0991, Test Accuracy: 0.9690\n",
      "\n",
      "Hidden Layers: 2, Units per Layer: 12\n",
      "Test Loss: 0.0971, Test Accuracy: 0.9687\n",
      "\n",
      "Hidden Layers: 2, Units per Layer: 24\n",
      "Test Loss: 0.0904, Test Accuracy: 0.9695\n",
      "\n",
      "Hidden Layers: 2, Units per Layer: 36\n",
      "Test Loss: 0.0874, Test Accuracy: 0.9710\n",
      "\n",
      "Hidden Layers: 3, Units per Layer: 12\n",
      "Test Loss: 0.0872, Test Accuracy: 0.9702\n",
      "\n",
      "Hidden Layers: 3, Units per Layer: 24\n",
      "Test Loss: 0.0869, Test Accuracy: 0.9705\n",
      "\n",
      "Hidden Layers: 3, Units per Layer: 36\n",
      "Test Loss: 0.0868, Test Accuracy: 0.9707\n",
      "\n",
      "Best Configuration: Hidden Layers: 2, Units per Layer: 36\n",
      "Best Test Accuracy: 0.9710\n"
     ]
    }
   ],
   "source": [
    "# Function that trains the model with the experimented architecture\n",
    "def experiment_architecture(hidden_layer, units_per_layer, input_train, output_train, input_test, output_test):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Build the input layer\n",
    "    model.add(keras.layers.InputLayer(input_shape=(input_train.shape[1], ))) # specifies that the input data has one dimension for each feature\n",
    "\n",
    "    # Add hidden layers as specified\n",
    "    for _ in range(hidden_layer):\n",
    "        model.add(keras.layers.Dense(\n",
    "                        units=units_per_layer,  # units depending on the experiment\n",
    "                        activation='relu'       # 'relu' => Rectified Linear Unit - common actvitation function in deep learning\n",
    "        ))\n",
    "        \n",
    "    # Build the output layer\n",
    "    model.add(keras.layers.Dense(\n",
    "                        units=1,                # since it is a binary classification problem (output => 0 or 1)\n",
    "                        activation='sigmoid'    # 'sigmoid' => common activation function for binary classification tasks\n",
    "    ))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',                       #  Adam optimizer => popular optimization algorithm\n",
    "        loss='binary_crossentropy',             # 'binary_crossentropy' => suitable for binary classification problems\n",
    "        metrics=['accuracy']                    #  model's performance will be evaluated using the 'accuracy' metric\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(                        \n",
    "        input_train,             \n",
    "        output_train, \n",
    "        epochs=10,                              #  iterations over the entire training dataset\n",
    "        batch_size=32,                          #  size of each batch used for training\n",
    "        validation_data=(input_test, output_test),\n",
    "        verbose=0                               #  training progress wont be printed on the console\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(input_test, output_test)\n",
    "\n",
    "    return history, test_loss, test_accuracy\n",
    "\n",
    "# Act as main function\n",
    "for hidden_layer in num_hidden_layers:\n",
    "    for units_per_layer in num_units_per_layer:\n",
    "        key = (hidden_layer, units_per_layer)\n",
    "        history, test_loss, test_accuracy = experiment_architecture(hidden_layer, units_per_layer, input_train, output_train, input_test, output_test)\n",
    "        results[key] = {'test_loss': test_loss, 'test_accuracy': test_accuracy}\n",
    "\n",
    "# Display the results\n",
    "for key, value in results.items():\n",
    "    hidden_layer, units_per_layer = key\n",
    "    test_loss = value['test_loss']\n",
    "    test_accuracy = value['test_accuracy']\n",
    "    \n",
    "    print(f\"Hidden Layers: {hidden_layer}, Units per Layer: {units_per_layer}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # Check if this configuration has the best accuracy so far\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_architecture = key\n",
    "\n",
    "# Print the best configuration and performance\n",
    "if best_architecture is not None:\n",
    "    print(f\"Best Configuration: Hidden Layers: {best_architecture[0]}, Units per Layer: {best_architecture[1]}\")\n",
    "    print(f\"Best Test Accuracy: {best_accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"No results found.\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment with different activation functions in the hidden layer\n",
    "\n",
    "1. ReLU (Rectified Linear Unit):\n",
    "    - Formula: f(x) = max(0, x)\n",
    "    - Range: [0, ∞)\n",
    "    - Advantages:\n",
    "        - Computationally efficient because it involves simple thresholding.\n",
    "        - Helps mitigate the vanishing gradient problem, which can occur with some other activation functions.\n",
    "        - Promotes sparse activation, meaning it can lead to sparsity in neural network activations, which can be beneficial.\n",
    "    - Commonly used in hidden layers of deep neural networks, especially for convolutional neural networks (CNNs) and feedforward networks.\n",
    "    <br/><br/>\n",
    "2. Sigmoid:\n",
    "    - Formula: f(x) = 1 / (1 + e^(-x))\n",
    "    - Range: (0, 1)\n",
    "    - Advantages:\n",
    "        - Outputs are squashed between 0 and 1, making it suitable for binary classification problems where you want to model probabilities.\n",
    "        - Well-suited for the output layer of binary classifiers.\n",
    "    - Disadvantages:\n",
    "        - Suffers from the vanishing gradient problem, particularly during backpropagation in deep networks.\n",
    "        - Not centered around zero, which can slow down training.\n",
    "        - Commonly used in the output layer for binary classification and in some older models.\n",
    "    <br/><br/>\n",
    "3. tanh (Hyperbolic Tangent):\n",
    "    - Formula: f(x) = (e^(x) - e^(-x)) / (e^(x) + e^(-x))\n",
    "    - Range: (-1, 1)\n",
    "    - Advantages:\n",
    "        - Similar to the sigmoid, but centered around zero, which can help in training deep networks.\n",
    "        - Captures both positive and negative values, making it suitable for tasks that involve capturing signed information.\n",
    "    - Disadvantages:\n",
    "        - Still suffers from the vanishing gradient problem, particularly in deep networks.\n",
    "        - Commonly used in hidden layers, especially in recurrent neural networks (RNNs) and older feedforward networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different activation functions\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Initialize variables to keep track of the best configuration and performance\n",
    "best_activation_function = None\n",
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1s 836us/step - loss: 0.0862 - accuracy: 0.9708\n",
      "938/938 [==============================] - 1s 807us/step - loss: 0.1111 - accuracy: 0.9614\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0902 - accuracy: 0.9690\n",
      "Activation Function: relu\n",
      "Test Loss: 0.0862, Test Accuracy: 0.9708\n",
      "\n",
      "Activation Function: sigmoid\n",
      "Test Loss: 0.1111, Test Accuracy: 0.9614\n",
      "\n",
      "Activation Function: tanh\n",
      "Test Loss: 0.0902, Test Accuracy: 0.9690\n",
      "\n",
      "Best Activation Function: relu\n",
      "Best Test Accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "def experiment_activation_function(activation_function, input_train, output_train, input_test, output_test):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(keras.layers.InputLayer(input_shape=(input_train.shape[1],)))   # specifies that the input data has one dimension for each feature\n",
    "    \n",
    "    # Hidden layers with specified activation function\n",
    "    model.add(keras.layers.Dense(units=64, activation=activation_function))   # 2 hidden layers with 64 units each with the given activation function\n",
    "    model.add(keras.layers.Dense(units=64, activation=activation_function))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(keras.layers.Dense(units=1, activation='sigmoid'))              # binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # same reason as above\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(input_train, output_train, epochs=10, batch_size=32, validation_data=(input_test, output_test), verbose=0) # same reason as above\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(input_test, output_test)\n",
    "    \n",
    "    return history, test_loss, test_accuracy\n",
    "\n",
    "# Act as the main function\n",
    "for activation_function in activation_functions:\n",
    "    history, test_loss, test_accuracy = experiment_activation_function(activation_function, input_train, output_train, input_test, output_test)\n",
    "    results[activation_function] = {'test_loss': test_loss, 'test_accuracy': test_accuracy}\n",
    "\n",
    "# Display the results\n",
    "for activation_function, value in results.items():\n",
    "    test_loss = value['test_loss']\n",
    "    test_accuracy = value['test_accuracy']\n",
    "    \n",
    "    print(f\"Activation Function: {activation_function}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # Check if this activation function has the best accuracy so far\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_activation_function = activation_function\n",
    "\n",
    "# Print the best-performing activation function and its accuracy\n",
    "if best_activation_function is not None:\n",
    "    print(f\"Best Activation Function: {best_activation_function}\")\n",
    "    print(f\"Best Test Accuracy: {best_accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"No results found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment with different optimizers\n",
    "\n",
    "1. Adam (Adaptive Moment Estimation):\n",
    "    - An extension of the stochastic gradient descent (SGD) optimization algorithm that combines the advantages of both the Adagrad and RMSprop optimizers.\n",
    "    - It uses adaptive learning rates for each parameter, meaning it automatically adjusts the learning rate during training based on the past gradients.\n",
    "    - Also includes momentum, which helps the optimization process by accumulating past gradients to speed up convergence.\n",
    "    - Key Hyperparameters:\n",
    "        - Learning rate (lr): Determines the step size during weight updates.\n",
    "        - Beta1 (beta1) and Beta2 (beta2): Exponential decay rates for the moment estimates. Common values are close to 1.\n",
    "        - Epsilon (epsilon): A small constant added to prevent division by zero.\n",
    "    - Advantages:\n",
    "        - Fast convergence for a wide range of problems.\n",
    "        - Works well with default hyperparameters for many tasks.\n",
    "        - Commonly used as a default optimizer choice.\n",
    "    <br/><br/>\n",
    "2. SGD (Stochastic Gradient Descent):\n",
    "    - One of the simplest optimization algorithms used in neural networks.\n",
    "    - It updates model weights based on the gradient of the loss function with respect to each parameter.\n",
    "    - SGD uses a fixed learning rate, which can be a challenge to tune for optimal performance.\n",
    "    - Key Hyperparameters:\n",
    "        - Learning rate (lr): Determines the step size during weight updates.\n",
    "    - Advantages:\n",
    "        - Simplicity and low memory requirements.\n",
    "        - Can be useful for small datasets or when fine-tuning pre-trained models.\n",
    "    - Disadvantages:\n",
    "        - Slower convergence compared to more advanced optimizers.\n",
    "        - Sensitive to the choice of learning rate and may require tuning.\n",
    "    <br/><br/>\n",
    "3. RMSprop (Root Mean Square Propagation):\n",
    "    - RMSprop is an adaptive learning rate optimization algorithm.\n",
    "    - It keeps a moving average of squared gradients for each weight and adapts the learning rate accordingly.\n",
    "    - RMSprop helps address the problem of rapidly decreasing learning rates in Adagrad by using a decaying average.\n",
    "    - Key Hyperparameters:\n",
    "        - Learning rate (lr): Determines the step size during weight updates.\n",
    "        - Decay rate (rho or beta): Controls the moving average of squared gradients. Common values are close to 0.9.\n",
    "        - Epsilon (epsilon): A small constant added to prevent division by zero.\n",
    "    - Advantages:\n",
    "        - Adaptive learning rates allow for faster convergence and better handling of different feature scales.\n",
    "        - Less sensitive to the choice of the learning rate compared to SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different optimizers\n",
    "optimizers = ['adam', 'sgd', 'rmsprop']\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Initialize variables to keep track of the best configuration and performance\n",
    "best_optimizer = None\n",
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0872 - accuracy: 0.9705\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1153 - accuracy: 0.9609\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0911 - accuracy: 0.9703\n",
      "Optimizer: adam\n",
      "Test Loss: 0.0872, Test Accuracy: 0.9705\n",
      "\n",
      "Optimizer: sgd\n",
      "Test Loss: 0.1153, Test Accuracy: 0.9609\n",
      "\n",
      "Optimizer: rmsprop\n",
      "Test Loss: 0.0911, Test Accuracy: 0.9703\n",
      "\n",
      "Best Optimizer: adam\n",
      "Best Test Accuracy: 0.9705\n"
     ]
    }
   ],
   "source": [
    "def experiment_optimizer(optimizer, input_train, output_train, input_test, output_test):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(keras.layers.InputLayer(input_shape=(input_train.shape[1],)))\n",
    "    \n",
    "    # Hidden layers\n",
    "    model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(keras.layers.Dense(units=1, activation='sigmoid'))  # Binary classification\n",
    "    \n",
    "    # Compile the model with the specified optimizer\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(input_train, output_train, epochs=10, batch_size=32, validation_data=(input_test, output_test), verbose=0)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(input_test, output_test)\n",
    "    \n",
    "    return history, test_loss, test_accuracy\n",
    "\n",
    "# Act as main function\n",
    "for optimizer in optimizers:\n",
    "    history, test_loss, test_accuracy = experiment_optimizer(optimizer, input_train, output_train, input_test, output_test)\n",
    "    results[optimizer] = {'test_loss': test_loss, 'test_accuracy': test_accuracy}\n",
    "\n",
    "# Display the results\n",
    "for optimizer, value in results.items():\n",
    "    test_loss = value['test_loss']\n",
    "    test_accuracy = value['test_accuracy']\n",
    "    \n",
    "    print(f\"Optimizer: {optimizer}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # Check if this optimizer has the best accuracy so far\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_optimizer = optimizer\n",
    "\n",
    "# Print the best-performing optimizer and its accuracy\n",
    "if best_optimizer is not None:\n",
    "    print(f\"Best Optimizer: {best_optimizer}\")\n",
    "    print(f\"Best Test Accuracy: {best_accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"No results found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Factors for the Final Architecture of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Configurations:\n",
      "Best Architecture: \n",
      "\tHidden Layers: 2, Units per Layer: 36\n",
      "Best Activation Function: relu\n",
      "Best Optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Configurations:\")\n",
    "print(\"Best Architecture: \")\n",
    "print(f\"\\tHidden Layers: {best_architecture[0]}, Units per Layer: {best_architecture[1]}\")\n",
    "print(f\"Best Activation Function: {best_activation_function}\")\n",
    "print(f\"Best Optimizer: {best_optimizer}\")\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1s 970us/step - loss: 0.0861 - accuracy: 0.9713\n",
      "Test Loss: 0.0861, Test Accuracy: 0.9713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def final_model(architecture, activation_function, optimizer, input_train, output_train, input_test, output_test):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(keras.layers.InputLayer(input_shape=(input_train.shape[1],)))\n",
    "    \n",
    "    # Hidden layers\n",
    "    for _ in range(architecture[0]):\n",
    "        model.add(keras.layers.Dense(units=architecture[1], activation=activation_function))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(keras.layers.Dense(units=1, activation='sigmoid'))  # Binary classification\n",
    "    \n",
    "    # Compile the model with the specified optimizer\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(input_train, output_train, epochs=10, batch_size=32, validation_data=(input_test, output_test), verbose=0)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(input_test, output_test)\n",
    "    \n",
    "    return history, test_loss, test_accuracy\n",
    "\n",
    "# Display the results\n",
    "history, test_loss, test_accuracy = final_model(best_architecture, best_activation_function, best_optimizer, input_train, output_train, input_test, output_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1s 732us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30000, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "prediction = model.predict(input_test)\n",
    "prediction = prediction[:, -1].reshape(-1, 1)\n",
    "prediction = np.array((prediction > 0.5))\n",
    "\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[21106  6355]\n",
      " [  959  1580]]\n",
      "\n",
      "Accuracy Score:  0.7562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output_test = np.array(output_test).flatten()\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(output_test, prediction)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nAccuracy Score: \", accuracy_score(output_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x750 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "# Display the confusion matrix as a heatmap with a blue color map and transparency\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "# Loop through rows and columns of the confusion matrix\n",
    "for row in range(conf_matrix.shape[0]):\n",
    "    for column in range(conf_matrix.shape[1]):\n",
    "        # Add text with the value of each cell in the center\n",
    "        ax.text(x=column, y=row, s=conf_matrix[row, column], va='center', ha='center', size='xx-large')\n",
    "\n",
    "# Set labels for the x and y axes\n",
    "plt.xlabel('Predicted Labels', fontsize=18)\n",
    "plt.ylabel('Actual Labels', fontsize=18)\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "**Training Accuracy (0.9713)**\n",
    "\n",
    "During training, your model achieved a high training accuracy of 0.976. This suggests that the model learned to fit the training data very well. However, a high training accuracy does not necessarily imply good generalization.\n",
    "\n",
    "**Testing Accuracy (0.756)**\n",
    "\n",
    "After making predictions on the test data, the accuracy dropped to 0.756. This indicates that the model is not performing as well on unseen data as it did on the training data.\n",
    "\n",
    "The most likely explanation for this drop in accuracy is *overfitting*. ***Overfitting*** occurs when the model becomes too complex and starts to learn noise in the training data rather than the underlying patterns. As a result, it fails to generalize well to new, unseen data.\n",
    "\n",
    "To resolve *overfitting*, possible imporvements to make:\n",
    "1. Add more data to train the model more accurately\n",
    "2. Experiment with different values of the 3 factors.\n",
    "3. Implement *early stopping* to monitor validation loss and stop the training when it starts increasing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
